{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "In this notebook we will implement a convolutional neural network. Rather than doing everything from scratch we will make use of [TensorFlow 2](https://www.tensorflow.org/) and the [Keras](https://keras.io) high level interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing TensorFlow and Keras\n",
    "\n",
    "TensorFlow and Keras are not included with the base Anaconda install, but can be easily installed by running the following commands on the Anaconda Command Prompt/terminal window:\n",
    "```\n",
    "conda install notebook jupyterlab nb_conda_kernels\n",
    "conda create -n tf tensorflow ipykernel mkl\n",
    "```\n",
    "Once this has been done, you should be able to select the `Python [conda env:tf]` kernel from the Kernel->Change Kernel menu item at the top of this notebook. Then, we import TensorFlow package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a simple network with TensorFlow\n",
    "\n",
    "We will start by creating a very simple fully connected feedforward network using TensorFlow/Keras. The network will mimic the one we implemented previously, but TensorFlow/Keras will take care of most of the details for us.\n",
    "\n",
    "### MNIST Dataset\n",
    "\n",
    "First, let us load the MNIST digits dataset that we will be using to train our network. This is available directly within Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data comes as a set of integers in the range [0,255] representing the shade of gray of a given pixel. Let's first rescale them to be in the range [0,1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build a neural network model using Keras. This uses a very simple high-level modular structure where we only have the specify the layers in our model and the properties of each layer. The layers we will have are as follows:\n",
    "1. Input layer: This will be a 28x28 matrix of numbers.\n",
    "2. `Flatten` layer: Convert our 28x28 pixel image into an array of size 784.\n",
    "3. `Dense` layer: a fully-connected layer of the type we have been using up to now. We will use 30 neurons and the sigmoid activation function.\n",
    "4. `Dense` layer: fully-connected output layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(30, activation='sigmoid'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we compile this model, specifying the optimization algorithm (ADAM) and loss function (cross-entropy) to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train the model with our training data. We will run for 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.5869 - accuracy: 0.8702\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.2649 - accuracy: 0.9273\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.2109 - accuracy: 0.9417\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1796 - accuracy: 0.9500\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.1582 - accuracy: 0.9556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f92784a4210>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we check the accuracy of our model against the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.15718528725653888, 0.9548]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has 95.5% accuracy, consistent with what was found during training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises\n",
    "Experiment with this network:\n",
    "1. Change the number of neurons in the hidden layer.\n",
    "2. Add more hidden layers.\n",
    "3. Change the activation function in the hidden layer to `relu` (for examples see the list of [Keras Layer Activation Functions](https://keras.io/api/layers/activations/)).\n",
    "4. Change the activation in the output layer to something other than `softmax`.\n",
    "5. Change the loss function (for examples see the list of [Keras Loss Functions](https://keras.io/api/losses/)).\n",
    "How does the performance of your network change with these modifications?\n",
    "\n",
    "#### Task\n",
    "Implement the neural network in \"[Gradient-based learning applied to document recognition](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)\", by Yann LeCun, LÃ©on Bottou, Yoshua Bengio, and Patrick Haffner. The [Keras Layer documentation](https://keras.io/api/layers/) includes information about the layers supported. In particular, [`Conv2D`](https://keras.io/api/layers/convolution_layers/convolution2d) and [`MaxPooling2D`](https://keras.io/api/layers/pooling_layers/max_pooling2d) layers may be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solution\n",
    "\n",
    "We first need to reshape the input data to make the images 28 x 28 x 1 rather than 28 x 28. This is beacause more generally we might have 28 x 28 x 3 to account for the three colour channels (red, green, blue) in an image, but here we have only one grayscale channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_train[..., np.newaxis]\n",
    "X_test = x_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also convert the y's to categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "Y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we construct our network with three convolution layers, two pooling layers and fully-connected layers at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(6, (5, 5), activation='relu', padding='same', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "  tf.keras.layers.Conv2D(16, (5, 5), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "  tf.keras.layers.Conv2D(120, (5, 5), activation='relu'),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(84, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compile the model, specfiying cross-entropy loss and ADAM optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the model for 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 35s 577us/sample - loss: 0.3140 - accuracy: 0.9076\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 36s 599us/sample - loss: 0.0849 - accuracy: 0.9739\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 38s 632us/sample - loss: 0.0601 - accuracy: 0.9812\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 39s 653us/sample - loss: 0.0476 - accuracy: 0.9851\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 39s 645us/sample - loss: 0.0399 - accuracy: 0.9873\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 39s 643us/sample - loss: 0.0328 - accuracy: 0.9895\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 39s 654us/sample - loss: 0.0284 - accuracy: 0.9909\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 40s 665us/sample - loss: 0.0235 - accuracy: 0.9923\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 40s 668us/sample - loss: 0.0210 - accuracy: 0.9929\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 42s 692us/sample - loss: 0.0192 - accuracy: 0.9935\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 42s 692us/sample - loss: 0.0171 - accuracy: 0.9942\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 41s 679us/sample - loss: 0.0140 - accuracy: 0.9954\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 42s 693us/sample - loss: 0.0134 - accuracy: 0.9956\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 43s 710us/sample - loss: 0.0118 - accuracy: 0.9961\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 41s 690us/sample - loss: 0.0111 - accuracy: 0.9962\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 44s 726us/sample - loss: 0.0101 - accuracy: 0.9968\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 44s 728us/sample - loss: 0.0094 - accuracy: 0.9968\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 42s 707us/sample - loss: 0.0078 - accuracy: 0.9972\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 42s 695us/sample - loss: 0.0080 - accuracy: 0.9971\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 43s 712us/sample - loss: 0.0070 - accuracy: 0.9976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f920876c710>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=128, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have achieved 99.6% accuracy after training for 20 epochs. Let's check this against the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.053945613601373774, 0.9853]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is 98.5%, so we may have slightly overtrained, but still have a highly accurate model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
